[DEFAULT]

[kinetica]

# The common JAR directory param is only used by this config file.
jar-dir = /mnt/data/spark/jars

# this must be a file on the master.
application-jar = ${kinetica:jar-dir}/fsq-spark-loader-1.0-SNAPSHOT.jar

[spark]

# Tuning
#spark.sql.shuffle.partitions = 1
#spark.driver.cores = 1
#spark.executor.cores = 1
#spark.executor.instances = 2
spark.logConf = false

# Additional JARS needed by te job
spark.jars = ${kinetica:jar-dir}/kinetica-jdbc-7.1.8.6-shaded.jar
    ,${kinetica:jar-dir}/aws-java-sdk-bundle-1.11.901.jar
    ,${kinetica:jar-dir}/hadoop-aws-3.3.1.jar

# Kinetica credentials
spark.4sq.jdbc.url = jdbc:kinetica://g-p100-300-301-u29.tysons.kinetica.com:9191
spark.4sq.jdbc.user = ingest
spark.4sq.jdbc.password.key = ???

# aws credentials
spark.hadoop.fs.s3a.access.key = ???
spark.hadoop.fs.s3a.secret.key = GAB2p+torn5b7vNULi7QA3w3h7x1NU98QhWT+t58

# AWS credentials for assumed role. If you are not using an assumed role then comment this section out.
# ref: https://www.aloneguid.uk/posts/2021/03/spark-s3-assume-role/
# ref: https://docs.aws.amazon.com/sdkref/latest/guide/feature-sts-regionalized-endpoints.html
# ref: https://hadoop.apache.org/docs/stable/hadoop-aws/tools/hadoop-aws/assumed_roles.html
# ref: https://docs.aws.amazon.com/sdk-for-java/v1/developer-guide/java-dg-region-selection.html
# ref: https://issues.apache.org/jira/browse/HADOOP-17771
spark.hadoop.fs.s3a.aws.credentials.provider = org.apache.hadoop.fs.s3a.auth.AssumedRoleCredentialProvider
spark.hadoop.fs.s3a.assumed.role.arn = arn:aws:iam::798457485286:role/foursquare-data-sharing
spark.hadoop.fs.s3a.assumed.role.session.name = kinetica-spark
spark.hadoop.fs.s3a.assumed.role.session.duration = 3600
spark.hadoop.fs.s3a.assumed.role.sts.endpoint = sts.us-east-1.amazonaws.com
spark.hadoop.fs.s3a.assumed.role.sts.endpoint.region = us-east-1

